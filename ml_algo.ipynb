{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ea85ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, precision_recall_curve, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c66473",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_ticks_to_candles(data, tick_count=20):\n",
    "    candles = []\n",
    "    data_sorted = data.sort_values('timestamp').reset_index(drop=True)\n",
    "    for i in range(0, len(data_sorted), tick_count):\n",
    "        chunk = data_sorted.iloc[i:i+tick_count]\n",
    "        if chunk.empty:\n",
    "            continue\n",
    "        candles.append({\n",
    "            'timestamp': chunk['timestamp'].iloc[0],\n",
    "            'open':      chunk['price'].iloc[0],\n",
    "            'high':      chunk['price'].max(),\n",
    "            'low':       chunk['price'].min(),\n",
    "            'close':     chunk['price'].iloc[-1],\n",
    "            'volume':    len(chunk)\n",
    "        })\n",
    "    return pd.DataFrame(candles)\n",
    "\n",
    "\n",
    "def calculate_rsi(prices, period=14):\n",
    "    delta = prices.diff()\n",
    "    gain = delta.where(delta > 0, 0).rolling(window=period).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n",
    "    rs = gain / loss\n",
    "    return 100 - (100 / (1 + rs))\n",
    "\n",
    "\n",
    "def calculate_technical_indicators(df):\n",
    "    df = df.copy()\n",
    "    df['ema_9']  = df['close'].ewm(span=9,  adjust=False).mean()\n",
    "    df['ema_15'] = df['close'].ewm(span=15, adjust=False).mean()\n",
    "    df['ema_21'] = df['close'].ewm(span=21, adjust=False).mean()\n",
    "    def _adx(high, low, close, period=5):\n",
    "        tr1 = high - low\n",
    "        tr2 = np.abs(high - close.shift(1))\n",
    "        tr3 = np.abs(low  - close.shift(1))\n",
    "        tr  = np.maximum(tr1, np.maximum(tr2, tr3))\n",
    "        dm_plus  = np.where((high - high.shift(1)) > (low.shift(1) - low),\n",
    "                             np.maximum(high - high.shift(1), 0), 0)\n",
    "        dm_minus = np.where((low.shift(1) - low) > (high - high.shift(1)),\n",
    "                             np.maximum(low.shift(1) - low, 0), 0)\n",
    "        tr_s   = pd.Series(tr).ewm(span=period, adjust=False).mean()\n",
    "        dmp_s  = pd.Series(dm_plus).ewm(span=period, adjust=False).mean()\n",
    "        dmm_s  = pd.Series(dm_minus).ewm(span=period, adjust=False).mean()\n",
    "        di_plus  = 100 * (dmp_s / tr_s)\n",
    "        di_minus = 100 * (dmm_s / tr_s)\n",
    "        dx       = 100 * np.abs(di_plus - di_minus) / (di_plus + di_minus)\n",
    "        return dx.ewm(span=period, adjust=False).mean()\n",
    "    df['adx'] = _adx(df['high'], df['low'], df['close'])\n",
    "    df['is_green']    = df['close'] > df['open']\n",
    "    df['returns']     = df['close'].pct_change()\n",
    "    df['body_size']   = np.abs(df['close'] - df['open']) / df['close']\n",
    "    df['upper_wick']  = (df['high'] - df[['open','close']].max(axis=1)) / df['close']\n",
    "    df['lower_wick']  = (df[['open','close']].min(axis=1) - df['low']) / df['close']\n",
    "    df['price_range'] = (df['high'] - df['low']) / df['close']\n",
    "    df['volatility']   = df['returns'].rolling(5).std()\n",
    "    df['volume_sma']   = df['volume'].rolling(5).mean()\n",
    "    df['volume_ratio'] = df['volume'] / df['volume_sma']\n",
    "    df['rsi']            = calculate_rsi(df['close'])\n",
    "    df['price_position'] = (df['close'] - df['low'].rolling(10).min()) / (\n",
    "                              df['high'].rolling(10).max() - df['low'].rolling(10).min())\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_enhanced_features(df, lookback=5):\n",
    "    features, labels = [], []\n",
    "    start = max(25, lookback + 2)\n",
    "    for i in range(start, len(df)-1):\n",
    "        if df['is_green'].iloc[i-2] and df['is_green'].iloc[i-1]:\n",
    "            curr = df.iloc[i-1]\n",
    "            base = [\n",
    "                curr['ema_9'] - curr['ema_15'], curr['ema_9'] - curr['ema_21'],\n",
    "                curr['adx'], curr['rsi'], curr['volatility'], curr['volume_ratio'],\n",
    "                curr['body_size'], curr['upper_wick'], curr['lower_wick'],\n",
    "                curr['price_position'], curr['returns'], curr['price_range']\n",
    "            ]\n",
    "            hist = []\n",
    "            for j in range(1, lookback+1):\n",
    "                if i-1-j >= 0:\n",
    "                    prev = df.iloc[i-1-j]\n",
    "                    hist += [prev['returns'], prev['body_size'], int(prev['is_green'])]\n",
    "                else:\n",
    "                    hist += [0,0,0]\n",
    "            row = np.nan_to_num(np.array(base + hist), nan=0, posinf=0, neginf=0)\n",
    "            features.append(row)\n",
    "            labels.append(int(df['is_green'].iloc[i]))\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "def train_and_save_model(train_file, model_path, tick_count=20, lookback=5):\n",
    "    ticks   = pd.read_csv(train_file)\n",
    "    candles = convert_ticks_to_candles(ticks, tick_count)\n",
    "    candles = calculate_technical_indicators(candles)\n",
    "    X, y    = create_enhanced_features(candles, lookback)\n",
    "\n",
    "    X_tr, X_val, y_tr, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    rf = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "    grid = GridSearchCV(rf, {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5],\n",
    "        'min_samples_leaf': [1, 2]\n",
    "    }, cv=3, scoring='precision', n_jobs=-1)\n",
    "    grid.fit(X_tr, y_tr)\n",
    "    best_model = grid.best_estimator_\n",
    "\n",
    "    proba = best_model.predict_proba(X_val)[:,1]\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_val, proba)\n",
    "    idx_perfect = np.where(precisions[:-1] == 1.0)[0]\n",
    "    if idx_perfect.size > 0:\n",
    "        best_idx = idx_perfect[np.argmax(recalls[idx_perfect])]\n",
    "    else:\n",
    "        best_idx = np.argmax(precisions[:-1])\n",
    "    best_thresh = thresholds[best_idx]\n",
    "\n",
    "    joblib.dump({'model': best_model, 'threshold': best_thresh}, model_path)\n",
    "    print(f\"[+] Saved RF + perfect-precision threshold={best_thresh:.3f} to {model_path}\")\n",
    "    return best_model, best_thresh\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, labels=[\"Not Green\", \"Green\"]):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot(cmap='Blues', values_format='d')\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.grid(False)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def load_model(model_path):\n",
    "    return joblib.load(model_path)\n",
    "\n",
    "\n",
    "def evaluate_on_test(test_file, loaded, tick_count=20, lookback=5):\n",
    "    model = loaded['model']\n",
    "    threshold = max(0.0, loaded['threshold'] - 0.2) \n",
    "    ticks = pd.read_csv(test_file)\n",
    "    candles = convert_ticks_to_candles(ticks, tick_count)\n",
    "    candles = calculate_technical_indicators(candles)\n",
    "    X_test, y_test = create_enhanced_features(candles, lookback)\n",
    "\n",
    "    proba = model.predict_proba(X_test)[:, 1]\n",
    "    y_pred = (proba >= threshold).astype(int)\n",
    "\n",
    "    p = precision_score(y_test, y_pred)\n",
    "    r = recall_score(y_test, y_pred)\n",
    "    a = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Precision @thr {threshold:.3f}: {p:.4f}\")\n",
    "    print(f\"Recall:                 {r:.4f}\")\n",
    "    print(f\"Accuracy:               {a:.4f}\")\n",
    "\n",
    "    plot_confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    return p, r, a\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    TRAIN_FILE = '/Users/sushanth/Desktop/Nano_scalping/Crypto/Data/btcusdc_ticks.csv'\n",
    "    TEST_FILE  = '/Users/sushanth/Desktop/Nano_scalping/Crypto/Data/BTC_USDC/binance_btcusdc_trades.csv'\n",
    "    MODEL_FILE = 'rf_third_green_precision.pkl'\n",
    "\n",
    "    model, thresh = train_and_save_model(TRAIN_FILE, MODEL_FILE, tick_count=10, lookback=5)\n",
    "    loaded = load_model(MODEL_FILE)\n",
    "    evaluate_on_test(TEST_FILE, loaded, tick_count=100, lookback=5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "freq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
